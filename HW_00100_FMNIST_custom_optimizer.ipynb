{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW 00100 FMNIST custom optimizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN4xavLLfR0b9WoD6SuOFRx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/briannewjawn/IST597/blob/ist-hw00100/HW_00100_FMNIST_custom_optimizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AX6v3H_xkwno"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "import pdb; \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.list_physical_devices('GPU')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmNuYeJjk6ih",
        "outputId": "c9f68e3f-3e4a-417e-ab5b-d812a238fe7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data() # Load MNIST or FMNIST\n",
        "assert X_train.shape == (60000, 28, 28)\n",
        "assert X_test.shape == (10000, 28, 28)\n",
        "assert y_train.shape == (60000,)\n",
        "assert y_test.shape == (10000,)\n",
        "\n",
        "\n",
        "# Display randomly selected data\n",
        "indices = list(np.random.randint(X_train.shape[0],size=3))\n",
        "for i in range(3):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plt.imshow(X_train[indices[i]].reshape(28,28), cmap='gray', interpolation='none')\n",
        "    plt.title(\"Index {} Class {}\".format(indices[i], y_train[indices[i]]))\n",
        "    plt.tight_layout()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "Glaatwuek7kh",
        "outputId": "93137a6b-38b1-4075-8b94-851141d10748"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train dataset into train and validation\n",
        "X_val = X_train[50000:60000]\n",
        "X_train = X_train[0:50000]\n",
        "y_val = y_train[50000:60000]\n",
        "y_train = y_train[0:50000]\n",
        "\n",
        "print(\"size of training set is\", str(X_train.shape[0]), \"samples\")\n",
        "print(\"every train example is\", str(X_train.shape[1]), \"by\", str(X_train.shape[2]))\n",
        "\n",
        "print(\"size of validation set is\", str(X_val.shape[0]), \"samples\")\n",
        "print(\"every validation example is\", str(X_val.shape[1]), \"by\", str(X_val.shape[2]))\n",
        "\n",
        "X_train = X_train.reshape(50000, 28*28)\n",
        "X_val = X_val.reshape(10000, 28*28)\n",
        "X_test = X_test.reshape(10000, 28*28)\n",
        "\n",
        "print(\"size of training set is\", str(X_train.shape[0]), \"samples\")\n",
        "print(\"every train example has\", str(X_train.shape[1]), \"features\")\n",
        "\n",
        "print(\"size of validation set is\", str(X_val.shape[0]), \"samples\")\n",
        "print(\"every validation example has\", str(X_val.shape[1]), \"features\")\n",
        "\n",
        "# Split dataset into batches\n",
        "#train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(16)\n",
        "#test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UEZWcoVlCBr",
        "outputId": "81e8351e-3ecd-4e9f-d12e-15a3f529c371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of training set is 50000 samples\n",
            "every train example is 28 by 28\n",
            "size of validation set is 10000 samples\n",
            "every validation example is 28 by 28\n",
            "size of training set is 50000 samples\n",
            "every train example has 784 features\n",
            "size of validation set is 10000 samples\n",
            "every validation example has 784 features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize Data\n",
        "\n",
        "X_train = X_train/255\n",
        "X_val = X_val/255\n",
        "X_test = X_test/255\n",
        "\n",
        "np.max(X_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1LJCIy4lGs7",
        "outputId": "c7b1604e-819f-48a9-fa50-75df69b82ebe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "size_input = X_train.shape[1]\n",
        "size_hidden1 = 128\n",
        "size_hidden2 = 128\n",
        "size_hidden3 = 128\n",
        "size_output = 10\n",
        "\n",
        "number_of_train_examples = X_train.shape[0]\n",
        "number_of_test_examples = X_test.shape[0]\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10) # Other function is tf.one_hot(y_train,depth=10)\n",
        "y_val = tf.keras.utils.to_categorical(y_val, num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "print(tf.shape(y_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKJGUrGplIdc",
        "outputId": "70ca7cf4-3759-449e-ea24-be17d0fd0aae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([10000    10], shape=(2,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GnF0f-Lh24JI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom Optimizer"
      ],
      "metadata": {
        "id": "0mAZWCktlWw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        " def __init__(self, size_input, size_hidden1, size_hidden2, size_hidden3, size_output,mt,vt,ut,device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden1: int, size of the 1st hidden layer\n",
        "    size_hidden2: int, size of the 2nd hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_hidden1, self.size_hidden2, self.size_hidden3, self.size_output,self.mt,self.vt,self.ut, self.device =\\\n",
        "    size_input, size_hidden1, size_hidden2, size_hidden3, size_output,mt,vt,ut, device\n",
        "    \n",
        "    # Initialize weights between input mapping and a layer g(f(x)) = layer\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden1],stddev=0.1)) # Xavier(Fan-in fan-out) and Orthogonal\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b1 = tf.Variable(tf.zeros([1, self.size_hidden1])) # 0 or constant(0.01)\n",
        "    \n",
        "    # Initialize weights between input layer and 1st hidden layer\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden1, self.size_hidden2],stddev=0.1))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b2 = tf.Variable(tf.zeros([1, self.size_hidden2]))\n",
        "    \n",
        "    # Initialize weights between 1st hidden layer and 2nd hidden layer\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_hidden2, self.size_hidden3],stddev=0.1))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b3 = tf.Variable(tf.zeros([1, self.size_hidden3]))\n",
        "    \n",
        "     # Initialize weights between 2nd hidden layer and output layer\n",
        "    self.W4 = tf.Variable(tf.random.normal([self.size_hidden3, self.size_output],stddev=0.1))\n",
        "    # Initialize biases for output layer\n",
        "    self.b4 = tf.Variable(tf.zeros([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.W4, self.b1, self.b2, self.b3, self.b4]\n",
        "    self.Wvariables =[self.W1, self.W2, self.W3,self.W4]\n",
        "    \n",
        "    \n",
        "  \n",
        " def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "\n",
        " def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    #y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_true_tf = tf.cast(y_true, dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "    regularizerL1L2 = tf.keras.regularizers.L1L2()\n",
        "    lossL1L2 = tf.add_n([regularizerL1L2(v) for v in self.Wvariables ])\n",
        "    loss_x = cce(y_true_tf, y_pred_tf) + 0.3*lossL1L2\n",
        "    # Use keras or tf_softmax, both should work for any given model\n",
        "    #loss_x = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred_tf, labels=y_true_tf))\n",
        "    \n",
        "    return loss_x\n",
        "\n",
        " def backward(self, X_train, y_train,epoch):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    #optimizer = tf.keras.optimizers.SGD(learning_rate = 0.1)\n",
        "    \n",
        "    with tf.GradientTape() as tape:\n",
        "        \n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "        \n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    #optimizer.apply_gradients(zip(grads, self.variables))\n",
        "\n",
        "    mt=self.mt\n",
        "    vt=self.vt\n",
        "    ut=self.ut\n",
        "\n",
        "    alpha = 2e-3\n",
        "    beta_1 = 0.9\n",
        "    beta_2 = 0.999\n",
        "    beta_3 = 0.999987\n",
        "    epsilon = 1e-8\n",
        "    t = epoch + 1\n",
        "\n",
        "    \n",
        "    for i in range(len(grads)):\n",
        "      #update bias moment estimate\n",
        "      mt[i] = beta_1*mt[i]+ (1-beta_1)*grads[i]\n",
        "      vt[i] = beta_2*vt[i]+(1-beta_2)*grads[i]**2\n",
        "      ut[i] = beta_3*ut[i] +(1-beta_3)*grads[i]**3\n",
        "\n",
        "      #update bias correction\n",
        "      mhat = mt[i]/(1-beta_1**t)\n",
        "      vhat = vt[i]/(1-beta_2**t)\n",
        "      uhat = ut[i]/(1-beta_3**t)\n",
        "      #update weights\n",
        "      self.variables[i].assign(self.variables[i] - alpha*mhat/(tf.sqrt(vhat) +((np.cbrt(uhat))*epsilon)))\n",
        "\n",
        " \n",
        "\n",
        "\n",
        " def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #X_tf = X\n",
        "    \n",
        "    # Compute values in hidden layers\n",
        "    z1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    h1 = tf.nn.relu(z1)\n",
        "    \n",
        "    z2 = tf.matmul(h1, self.W2) + self.b2\n",
        "    h2 = tf.nn.relu(z2)\n",
        "    \n",
        "    z3 = tf.matmul(h2, self.W3) + self.b3\n",
        "    h3 = tf.nn.relu(z3)\n",
        "\n",
        "    # Compute output\n",
        "    output = tf.matmul(h3, self.W4) + self.b4\n",
        "    \n",
        "    #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this \n",
        "    # Second add tf.Softmax(output) and then return this variable\n",
        "    return (output)\n",
        "\n",
        "#  def stderr(self,y_pred):\n",
        "#     \"\"\"\n",
        "#      Calculate standard error\n",
        "#      \"\"\"\n",
        "#     y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "#     std_dev = np.std(y_pred_tf) #Calculates standard deviation\n",
        "#     std_err = std_dev/sqrt(len(y_pred_tf))\n",
        "#     return std_err \n",
        "\n",
        "\n",
        "#  def var(self,y_pred):\n",
        "#     \"\"\"\n",
        "#      Calculate variance \n",
        "#      \"\"\"\n",
        "#     y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "#     std_dev = np.std(y_pred_tf) #Calculates standard deviation\n",
        "#     variance = (std_dev**2) # calculate variance\n",
        "#     return variance "
      ],
      "metadata": {
        "id": "YGbCHGz6lMu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 10\n",
        "mt,vt,ut =[0]*8,[0]*8,[1e-6]*8  \n",
        "# Initialize model using CPU\n",
        "mlp_on_cpu = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output,mt,vt,ut, device='gpu')\n",
        "\n",
        "time_start = time.time()\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    \n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "    \n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(3455)).batch(128)\n",
        "  kz = 0\n",
        "  accuracy_z = 0.0\n",
        "  cur_train_acc = 0.0\n",
        "  for inputs, outputs in train_ds:\n",
        "    qw, tr = tf.shape(inputs)\n",
        "    kz = kz + 1\n",
        "    preds = mlp_on_cpu.forward(inputs) \n",
        "    loss_total = loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
        "    mlp_on_cpu.backward(inputs, outputs,epoch)\n",
        "\n",
        "\n",
        "  preds = mlp_on_cpu.forward(X_train)\n",
        "  # Get probs, remember we only have logits from our forward function, we need to apply softmax on top of it to get probs\n",
        "  preds = tf.nn.softmax(preds)\n",
        "  correct_prediction = tf.equal(tf.argmax(preds, 1), tf.argmax(y_train, 1))\n",
        "  accuracy_z = accuracy_z + tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  cur_train_acc += accuracy_z.numpy()\n",
        "  ds = cur_train_acc\n",
        "  print('\\nTrain Accuracy: {:.4f}'.format(ds))\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {} '.format(epoch + 1, np.sum(loss_total) / X_train.shape[0]))\n",
        "  preds_val = mlp_on_cpu.forward(X_val)\n",
        "  preds_val = tf.nn.softmax(preds_val)\n",
        "  correct_prediction = tf.equal(tf.argmax(preds_val, 1), tf.argmax(y_val, 1))\n",
        "\n",
        "  # Calculate accuracy\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  cur_val_acc = accuracy.numpy()\n",
        "\n",
        "  print('\\nValidation Accuracy: {:.4f}'.format(cur_val_acc))\n",
        "  \n",
        "  plt.plot(epoch + 1, np.sum(loss_total) / X_train.shape[0], 'go')\n",
        "\n",
        "        \n",
        "time_taken = time.time() - time_start\n",
        "    \n",
        "# Validate model\n",
        "    \n",
        "\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs"
      ],
      "metadata": {
        "id": "W9zqHw2-lPSl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "22bf0f50-f652-42ea-ec2b-f96efa5f11fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Accuracy: 0.8599\n",
            "Number of Epoch = 1 - Average Cross Entropy:= 0.003977196350097656 \n",
            "\n",
            "Validation Accuracy: 0.8500\n",
            "\n",
            "Train Accuracy: 0.8790\n",
            "Number of Epoch = 2 - Average Cross Entropy:= 0.0028158868408203123 \n",
            "\n",
            "Validation Accuracy: 0.8671\n",
            "\n",
            "Train Accuracy: 0.8888\n",
            "Number of Epoch = 3 - Average Cross Entropy:= 0.0025401939392089845 \n",
            "\n",
            "Validation Accuracy: 0.8735\n",
            "\n",
            "Train Accuracy: 0.8940\n",
            "Number of Epoch = 4 - Average Cross Entropy:= 0.002381898193359375 \n",
            "\n",
            "Validation Accuracy: 0.8801\n",
            "\n",
            "Train Accuracy: 0.8988\n",
            "Number of Epoch = 5 - Average Cross Entropy:= 0.0022622451782226562 \n",
            "\n",
            "Validation Accuracy: 0.8809\n",
            "\n",
            "Train Accuracy: 0.9020\n",
            "Number of Epoch = 6 - Average Cross Entropy:= 0.0021639865112304687 \n",
            "\n",
            "Validation Accuracy: 0.8831\n",
            "\n",
            "Train Accuracy: 0.9051\n",
            "Number of Epoch = 7 - Average Cross Entropy:= 0.002081480407714844 \n",
            "\n",
            "Validation Accuracy: 0.8844\n",
            "\n",
            "Train Accuracy: 0.9083\n",
            "Number of Epoch = 8 - Average Cross Entropy:= 0.002010756378173828 \n",
            "\n",
            "Validation Accuracy: 0.8846\n",
            "\n",
            "Train Accuracy: 0.9105\n",
            "Number of Epoch = 9 - Average Cross Entropy:= 0.0019451614379882812 \n",
            "\n",
            "Validation Accuracy: 0.8847\n",
            "\n",
            "Train Accuracy: 0.9129\n",
            "Number of Epoch = 10 - Average Cross Entropy:= 0.0018868190002441407 \n",
            "\n",
            "Validation Accuracy: 0.8843\n",
            "\n",
            "Total time taken (in seconds): 200.98\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "correct_test_prediction = tf.Variable(0, dtype=tf.float32)\n",
        "#test_loss_total = 0.0\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).shuffle(25, seed=epoch*(3455)).batch(128)\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_cpu.forward(inputs)\n",
        "  #b = mlp_on_default.loss(preds, outputs)\n",
        "  test_loss_total = test_loss_total +mlp_on_cpu.loss(preds, outputs)\n",
        "  \n",
        "  \n",
        "  for i in range(preds.shape[0]):\n",
        "    if tf.argmax(preds[i])== tf.argmax(outputs[i]):\n",
        "      correct_test_prediction = correct_test_prediction + 1.0\n",
        "  \n",
        "\n",
        "# a = (test_loss_total.numpy() / X_train.shape[0])\n",
        "# print(X_train.shape[0])\n",
        "# print(test_loss_total.numpy())\n",
        "# print(b)\n",
        "accuracytest = correct_test_prediction/X_test.shape[0]*100\n",
        "print('Test CCE: {:.4f}'.format(np.sum(test_loss_total.numpy()) / X_train.shape[0]))\n",
        "print('test accuracy = {}'.format(accuracytest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVzxHIDDHvEe",
        "outputId": "509c3b98-7a6d-4265-f02f-0a7a472c7b8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test CCE: 0.0005\n",
            "test accuracy = 87.9000015258789\n"
          ]
        }
      ]
    }
  ]
}